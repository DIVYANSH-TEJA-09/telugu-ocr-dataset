{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Telugu OCR Pipeline - SET 4 (1997-2012)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!apt-get install -y tesseract-ocr tesseract-ocr-tel\n",
                "!pip install pytesseract rapidfuzz opencv-python tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SET_NAME = 'set4'\n",
                "DRIVE_ROOT = '/content/drive/MyDrive'\n",
                "SOURCE_IMAGES = f'{DRIVE_ROOT}/{SET_NAME}/source_images/images'\n",
                "GROUND_TRUTH = f'{DRIVE_ROOT}/{SET_NAME}/ground_truth'\n",
                "OUTPUT_DIR = f'{DRIVE_ROOT}/output_{SET_NAME}'\n",
                "MIN_LINES = 4\n",
                "MIN_MATCH_SCORE = 95"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pytesseract, cv2, numpy as np, json, shutil, re, os\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom rapidfuzz import fuzz\nfrom tqdm.notebook import tqdm\n\nSOURCE_IMAGES_DIR = Path(SOURCE_IMAGES)\nGROUND_TRUTH_DIR = Path(GROUND_TRUTH)\nOUTPUT = Path(OUTPUT_DIR)\n\ndef split_into_sentences(text):\n    chunks = re.split(r'[.\\nà¥¤]+', text)\n    return [s.strip() for s in chunks if s.strip() and len(s.strip()) > 5]\n\ndef find_best_sentence_range(tesseract_text, sentences):\n    if not tesseract_text.strip() or not sentences: return None, 0\n    clean_tess = ' '.join(tesseract_text.split())\n    tess_len = len(clean_tess)\n    best_match, best_score = None, 0\n    for size in range(1, min(16, len(sentences) + 1)):\n        for start in range(len(sentences) - size + 1):\n            combined = ' '.join(sentences[start:start + size])\n            if len(combined) < tess_len * 0.7: continue\n            score = fuzz.ratio(clean_tess, combined)\n            if score > best_score: best_score, best_match = score, combined\n    return best_match, best_score\n\ndef build_story_index():\n    page_to_story = {}\n    for json_file in tqdm(list(GROUND_TRUTH_DIR.rglob('*.json')), desc='Indexing GT'):\n        try:\n            with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n        except: continue\n        pdf_stem = json_file.stem\n        stories = data.get('stories', [])\n        if not stories and 'story' in data: stories = [data['story']]\n        if not stories and 'content' in data: stories = [data]\n        for story in stories:\n            content = story.get('content', '')\n            if not content: continue\n            try:\n                start_page = int(story.get('pdf_page_start', 1))\n                end_page = int(story.get('pdf_page_end', start_page))\n                for page in range(start_page, end_page + 1):\n                    key = (pdf_stem, page)\n                    page_to_story[key] = page_to_story.get(key, '') + '\\n' + content\n            except: continue\n    return page_to_story\n\ndef parse_page_number(filename):\n    match = re.search(r'page[_-]?(\\d+)', Path(filename).stem, re.IGNORECASE)\n    if match: return int(match.group(1))\n    match = re.search(r'(\\d+)$', Path(filename).stem)\n    return int(match.group(1)) if match else None\n\ndef extract_and_align(img_path, gt_text, output_dir, unique_id):\n    results = []\n    img = cv2.imread(str(img_path))\n    if img is None: return results\n    try: data = pytesseract.image_to_data(img, lang='tel', output_type=pytesseract.Output.DICT)\n    except: return results\n    paragraphs = defaultdict(list)\n    for i in range(len(data['text'])):\n        text, conf = data['text'][i].strip(), int(data['conf'][i])\n        if conf > 0 and text:\n            paragraphs[(data['block_num'][i], data['par_num'][i])].append({'text': text, 'x': data['left'][i], 'y': data['top'][i], 'w': data['width'][i], 'h': data['height'][i], 'line_num': data['line_num'][i]})\n    sentences = split_into_sentences(gt_text)\n    if not sentences: return results\n    img_h, img_w = img.shape[:2]\n    para_idx = 0\n    for key, words in paragraphs.items():\n        if not words: continue\n        x_min, y_min = max(0, min(w['x'] for w in words) - 10), max(0, min(w['y'] for w in words) - 10)\n        x_max, y_max = min(img_w, max(w['x'] + w['w'] for w in words) + 10), min(img_h, max(w['y'] + w['h'] for w in words) + 10)\n        if x_max - x_min < 50 or y_max - y_min < 20: continue\n        lines_dict = defaultdict(list)\n        for w in sorted(words, key=lambda w: (w['line_num'], w['x'])): lines_dict[w['line_num']].append(w['text'])\n        if len(lines_dict) < MIN_LINES: continue\n        tess_text = '\\n'.join(' '.join(ws) for ws in lines_dict.values())\n        matched_gt, score = find_best_sentence_range(tess_text, sentences)\n        if score < MIN_MATCH_SCORE or not matched_gt: continue\n        para_id = f'{unique_id}_para_{para_idx:02d}'\n        cv2.imwrite(str(output_dir / f'{para_id}.jpg'), img[y_min:y_max, x_min:x_max])\n        results.append({'id': para_id, 'image': f'{para_id}.jpg', 'text': matched_gt, 'match_score': score, 'line_count': len(lines_dict)})\n        para_idx += 1\n    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'ðŸš€ Processing {SET_NAME}')\n",
                "if OUTPUT.exists(): shutil.rmtree(OUTPUT)\n",
                "OUTPUT.mkdir(parents=True); (OUTPUT / 'images').mkdir()\n",
                "\n",
                "page_to_story = build_story_index()\n",
                "all_images = list(SOURCE_IMAGES_DIR.rglob('*.jpg'))\n",
                "print(f'Images: {len(all_images)}')\n",
                "\n",
                "all_results, stats = [], {'processed': 0, 'with_gt': 0, 'extracted': 0}\n",
                "for img_path in tqdm(all_images, desc='Processing'):\n",
                "    stats['processed'] += 1\n",
                "    pdf_stem = img_path.parent.name.replace(' ', '_')\n",
                "    page_num = parse_page_number(img_path.name)\n",
                "    if page_num is None: continue\n",
                "    gt_text = page_to_story.get((pdf_stem, page_num))\n",
                "    if not gt_text: continue\n",
                "    stats['with_gt'] += 1\n",
                "    results = extract_and_align(img_path, gt_text, OUTPUT / 'images', f'{img_path.parent.parent.name}_{pdf_stem}_p{page_num:03d}')\n",
                "    if results: stats['extracted'] += len(results); all_results.extend(results)\n",
                "\n",
                "with open(OUTPUT / 'metadata.jsonl', 'w', encoding='utf-8') as f:\n",
                "    for item in all_results: f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
                "\n",
                "print(f'\\nâœ… Done! Output: {OUTPUT}')\n",
                "print(f'   Processed: {stats[\"processed\"]}, With GT: {stats[\"with_gt\"]}, Extracted: {stats[\"extracted\"]}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}